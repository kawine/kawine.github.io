<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Kawin Ethayarajh</title>

    <!-- Bootstrap -->
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

    <!-- Latest compiled and minified JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"/>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">
      body { 
        font-family: "Helvetica"; 
        margin-top: 5%;
      }

      h5 {
        font-size: 14px; 
        color: grey 
      }

      .top-buffer { margin-top: 40px; }
      .year { margin-top: 30px; margin-bottom: 10px; }
      .bottom-buffer { margin-bottom: 40px; }

      #pubs li { margin: 15px 0px; }

      @media (min-width: 992px) {
        .sidebar {
          position: fixed;
        }

        #portrait {
          width: 18%;
        }
      }

      @media (max-width: 992px) {
        .sidebar {
          padding-bottom: 5%;	
          margin: auto;
          text-align: center;
        }

        #portrait {
          width: 50%;
        }
      }
    </style>
  </head>

  <body>
    <div class="container">
      <div class="col-md-4">
        <div class="row sidebar">
            <img id="portrait" src="assets/new_profile.jpeg">
            <div class="year" style="font-size:19pt; font-weight: 300">
              <b class="name">KAWIN</b> ETHAYARAJH 
            </div>
            <i class="fa fa-fw fa-map-marker"></i> Stanford, CA<br>
            <i class="fa fa-fw fa-envelope"></i> firstname@stanford.edu</a><br>
            <a href="https://twitter.com/ethayarajh"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a><br>
            <a href="https://scholar.google.ca/citations?user=7SUV6rQAAAAJ&hl=en"><i class="fa fa-fw fa-google"></i> Google Scholar</a><br>
            <a href="https://github.com/kawine"><i class="fa fa-fw fa-github"></i> Github</a><br>
	          <a href="assets/CV.pdf"><i class="fa fa-fw fa-file"></i> CV</a><br>
          
        </div>
      </div>

      <div class="col-md-8 bottom-buffer">
  
          <div class="col-12">
		<p>
			I'm a fourth-year PhD student at Stanford NLP, advised by <a href="https://web.stanford.edu/~jurafsky/">Dan Jurafsky</a> and supported by a <a href="https://research.fb.com/fellowship/">Facebook Fellowship</a>.
		</p>
		<p>
			Evaluation in NLP is often reduced to a convenient one-dimensional metric, like test accuracy on a fixed dataset. My research takes a more expansive view, contending that NLP—and AI more broadly—should be evaluated along multiple dimensions and at every point in the pipeline. Some directions I’ve explored are: 
		</p>
		<p>
			<ul style="list-style: none">
				<li><b>Evaluating Data</b>: Does the training data represent the task it purports to reflect?</li>
				<li><b>Evaluating Metrics</b>: Are we using the right tool for the job?</li>
				<li><b>Evaluating Utility</b>: How can we measure how useful our systems are to real people?</li>
			</ul>
		</p>
		<p>	
			I've received an Oustanding Paper Award at ICML 2022 and a Best Paper Award at Repl4NLP @ ACL 2018. Prior to Stanford, I received an M.Sc. and B.Sc. at the University of Toronto, where I was advised by <a href="http://www.cs.toronto.edu/~gh/" target="_blank">Graeme Hirst</a> and worked with <a href="http://www.cs.toronto.edu/~duvenaud/" target="_blank">David Duvenaud</a> and <a href="http://www.cs.toronto.edu/~frank/" target="_blank">Frank Rudzicz</a>.
          </div>

        <h4 class="top-buffer">Research Highlights</h4>
        <ul style='margin-bottom: 50px; list-style: none' id="pubs">
		
 	  <h5 class="year">Evaluating Real-World Utility</h5>

	   <li>
		<i>The Authenticity Gap in Human Evaluation.</i><br/>
		<u>Kawin Ethayarajh</u> and Dan Jurafsky.<br/>
	      	EMNLP 2022.<br/>
	    	<a href="assets/emnlp_2022_paper.pdf"><span class="label label-default">paper</span></a>
	    	<a href="https://twitter.com/ethayarajh/status/1593028231707643904"><span class="label label-info">tweet</span></a>
	   </li>
		
	   <li>
		<i>Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking.</i><br/>
		Zhiyi Ma<sup>*</sup>, <u>Kawin Ethayarajh</u><sup>*</sup>, Tristan Thrush<sup>*</sup>, Somya Jain, Ledell Wu, Robin Jia, Christopher Potts, Adina Williams, Douwe Kiela. (*= equal contribution)<br/>
	      	NeurIPS 2021. <br/>
	    	<a href="https://proceedings.neurips.cc/paper/2021/hash/55b1927fdafef39c48e5b73b5d61ea60-Abstract.html"><span class="label label-default">paper</span></a>
		<a href="https://twitter.com/douwekiela/status/1396878157941145600"><span class="label label-info">tweet</span></a>
		<a href="https://dynabench.org/"><span class="label label-success">demo</span></a>
		<a href="https://venturebeat.com/2021/05/24/facebooks-dynabench-now-scores-nlp-models-for-metrics-like-fairness/"><span class="label label-danger">news</span></a> 
		<a href="https://proceedings.neurips.cc/paper/2021/hash/55b1927fdafef39c48e5b73b5d61ea60-Abstract.html"><span class="label label-primary">bib</span></a>		 
	  </li>
		
	  <li>
		<i>Utility is in the Eye of the User: A Critique of NLP Leaderboards.</i><br/>
            	<u>Kawin Ethayarajh</u> and Dan Jurafsky.<br/>
	    	EMNLP 2020.<br/>
	    	<a href="https://www.aclweb.org/anthology/2020.emnlp-main.393/"><span class="label label-default">paper</span></a>
	    	<a href="https://twitter.com/ethayarajh/status/1311399326413922304"><span class="label label-info">tweet</span></a>
        	<a href="https://www.aclweb.org/anthology/2020.emnlp-main.393.bib"><span class="label label-primary">bib</span></a>
          </li>
          
	   <h5 class="year">Evaluating Data</h5>
		
	   <li>
		<i>Understanding Dataset Difficulty with V-Usable Information.</i><br/>
		<u>Kawin Ethayarajh</u>, Yejin Choi, and Swabha Swayamdipta.<br/>
		ICML 2022 (<b>outstanding paper</b>).<br/>
	    	<a href="https://proceedings.mlr.press/v162/ethayarajh22a/ethayarajh22a.pdf"><span class="label label-default">paper</span></a>
	    	<a href="https://twitter.com/ethayarajh/status/1449203922057400329"><span class="label label-info">tweet</span></a>
		<a href="https://github.com/kawine/dataset_difficulty"><span class="label label-success">code</span></a>
        	<a href="https://proceedings.mlr.press/v162/ethayarajh22a.html"><span class="label label-primary">bib</span></a>
	  </li>
		
          <li>
		<i>Conditional Probing: Measuring Usable Information Beyond a Baseline.</i><br/>
            	John Hewitt, <u>Kawin Ethayarajh</u>, Percy Liang, and Christopher Manning.<br/>
	    	EMNLP 2021.<br/>
	    	<a href="https://aclanthology.org/2021.emnlp-main.122/"><span class="label label-default">paper</span></a>
	    	<a href="https://twitter.com/johnhewtt/status/1440384033255407625"><span class="label label-info">tweet</span></a>
		<a href="https://github.com/john-hewitt/conditional-probing"><span class="label label-success">code</span></a>
        	<a href="https://aclanthology.org/2021.emnlp-main.122.bib"><span class="label label-primary">bib</span></a>
          </li>

	  <h5 class="year">Evaluating Metrics</h5>

          <li>
            	<i>How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings.</i><br/>
            	<u>Kawin Ethayarajh</u>.<br/>
	    	EMNLP 2019.<br/>
	    	<a href="https://www.aclweb.org/anthology/D19-1006"><span class="label label-default">paper</span></a>
	    	<a href="https://twitter.com/ethayarajh/status/1225843038099931137"><span class="label label-info">tweet</span></a>
		<a href="https://kawine.github.io/blog/nlp/2020/02/03/contextual.html"><span class="label label-danger">blog</span></a>
		<a href="https://github.com/kawine/contextual"><span class="label label-success">code</span></a>
	    	<a href="https://www.aclweb.org/anthology/D19-1006.bib"><span class="label label-primary">bib</span></a>
          </li>

	  <li>
          	<i>Understanding Undesirable Word Embedding Associations.</i><br/>
          	<u>Kawin Ethayarajh</u>, David Duvenaud, and Graeme Hirst.<br/>
		ACL 2019.<br/>
		<a href="https://www.aclweb.org/anthology/P19-1166"><span class="label label-default">paper</span></a>
	    	<a href="https://twitter.com/ethayarajh/status/1180181274675138560"><span class="label label-info">tweet</span></a>
		<a href="https://kawine.github.io/blog/nlp/2019/09/23/bias.html"><span class="label label-danger">blog</span></a>
		<a href="https://www.aclweb.org/anthology/P19-1166.bib"><span class="label label-primary">bib</span></a>
          </li>
		
	  <li>
          	<i>Towards Understanding Linear Word Analogies.</i><br/>
          	<u>Kawin Ethayarajh</u>, David Duvenaud, and Graeme Hirst.<br/>
          	ACL 2019.<br/>
		<a href="https://www.aclweb.org/anthology/P19-1315"><span class="label label-default">paper</span></a>
		<a href="assets/acl_analogies_notes.txt"><span class="label label-default">addendum</span></a>
	    	<a href="https://twitter.com/ethayarajh/status/1142854783377690625"><span class="label label-info">tweet</span></a>
		<a href="https://kawine.github.io/blog/nlp/2019/06/21/word-analogies.html"><span class="label label-danger">blog</span></a>
		<a href="https://www.aclweb.org/anthology/P19-1315.bib"><span class="label label-primary">bib</span></a>
          </li>
		
          <li>
          	<i>Unsupervised Random Walk Sentence Embeddings: A Strong but Simple Baseline.</i><br/>
          	<u>Kawin Ethayarajh</u>.<br/>
          	ACL 2018 - Repl4NLP (<b>best paper</b>).<br/>
		<a href="https://www.aclweb.org/anthology/W18-3012"><span class="label label-default">paper</span></a>
		<a href="https://github.com/kawine/usif"><span class="label label-success">code</span></a>
		<a href="https://www.aclweb.org/anthology/W18-3012.bib"><span class="label label-primary">bib</span></a>
          </li>

        </ul>
      </div>

    </div> <!-- /container -->
  </body>
</html>
