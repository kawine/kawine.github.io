<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Kawin Ethayarajh</title>

    <!-- Bootstrap -->
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

    <!-- Latest compiled and minified JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"/>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">
      body { 
        font-family: "Helvetica"; 
        margin-top: 5%;
      }

      h5 {
        font-size: 14px; 
        color: grey 
      }

      .top-buffer { margin-top: 40px; }
      .year { margin-top: 30px; margin-bottom: 10px; }
      .bottom-buffer { margin-bottom: 40px; }

      #pubs li { margin: 15px 0px; }

      @media (min-width: 992px) {
        .sidebar {
          position: fixed;
        }

        #portrait {
          width: 18%;
        }
      }

      @media (max-width: 992px) {
        .sidebar {
          padding-bottom: 5%;	
          margin: auto;
          text-align: center;
        }

        #portrait {
          width: 50%;
        }
      }
    </style>
  </head>

  <body>
    <div class="container">
      <div class="col-md-4">
        <div class="row sidebar">
            <img id="portrait" src="assets/new_profile.jpeg">
            <div class="year" style="font-size:19pt; font-weight: 300">
              <b class="name">KAWIN</b> ETHAYARAJH 
            </div>
            <i class="fa fa-fw fa-map-marker"></i> Chicago, IL<br>
            <i class="fa fa-fw fa-envelope"></i> kawin.ethayarajh@chicagobooth.edu</a><br>
            <a href="https://twitter.com/ethayarajh"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a><br>
            <a href="https://scholar.google.ca/citations?user=7SUV6rQAAAAJ&hl=en"><i class="fa fa-fw fa-google"></i> Google Scholar</a><br>
            <a href="https://github.com/kawine"><i class="fa fa-fw fa-github"></i> Github</a><br>
	          <a href="assets/CV.pdf"><i class="fa fa-fw fa-file"></i> CV</a><br>
          
        </div>
      </div>

      <div class="col-md-8 bottom-buffer">
  
          <div class="col-12">
		<p>
			I am an <b>Assistant Professor of Applied AI</b> and <b>Kathryn and Grant Swick Faculty Scholar</b> at <b>UChicago Booth</b>, where I work on behavioral machine learning.
		</p>
		<p>
			Machine learning is not a sterile industrial process; much in the way that it is hardware-bound and software-bound, it is also bound by the behavior of real-world actors such as workers, firms, and states. 
			By borrowing from fields like economics, my work tries to formalize this behavior and create algorithms, tools, and systems that are compatible with actual actors, not just idealized ones.
		</p>
		<p>
			My work has received an <b>ICML 2022 Outstanding Paper</b> award, a <b>Facebook Fellowship</b>, and an <b>NSERC PGS-D</b>.
			Prior to UChicago, I graduated with a PhD in Computer Science from Stanford University, where I was advised by Dan Jurafsky.
			I have also spent time at Princeton Language & Intelligence (post-doc) and the University of Toronto (MSc, BSc).
		</p>
		<p>
			Notable work:
			<ul style="list-style-type: circle;" id="contributions">
				<li>
					A new framework for understanding dataset difficulty, based on the notion of <i>V-usable information</i>. 
					This led to the development of <b>Stanford Human Preferences (SHP)</b>, the first large-scale open-source dataset of human preferences over text, based on data from Reddit and StackExchange. 
					SHP was the only dataset not from Meta/OpenAI/Anthropic used to post-train Llama-2, one of the most downloaded LLMs ever. 
					Within a year of SHP's release, Reddit started licensing its data for AI training in deals valued at 200M+.
					<ul style='margin-bottom: 25px; list-style: none' id="pubs">
					  <li>  
						<i>Understanding Dataset Difficulty with V-Usable Information.</i><br/>
						<u>Kawin Ethayarajh</u>, Yejin Choi, and Swabha Swayamdipta.<br/>
						ICML 2022 (<b>outstanding paper</b> - top 10 of 1233 accepted).<br/>
						<a href="https://arxiv.org/abs/2110.08420"><span class="label label-default">paper</span></a>
						<a href="https://twitter.com/ethayarajh/status/1449203922057400329"><span class="label label-info">tweet 1</span></a>
						<a href="https://twitter.com/ethayarajh/status/1628442002454085632?lang=en"><span class="label label-info">tweet 2</span></a>
						<a href="https://github.com/kawine/dataset_difficulty"><span class="label label-success">code</span></a>
						<a href="https://huggingface.co/datasets/stanfordnlp/SHP"><span class="label label-danger">dataset 1</span></a>
						<a href="https://huggingface.co/datasets/stanfordnlp/SHP-2"><span class="label label-danger">dataset 2</span></a>
					  </li>
					</ul>
				</li>

				<li>
					Existing post-training objectives (PPO, DPO) unintentionally capture qualities of human utility functions, such as loss aversion, but we can design even better objectives by intentionally incorporating human biases.
					One of my proposed objectives, <b>KTO</b>, is the industry standard for aligning LLMs on binary feedback, especially in class-imbalanced settings that are typical of the real world.

					<ul style='margin-bottom: 25px; list-style: none' id="pubs">
						<li>	
							<i>Model Alignment as Prospect Theoretic Optimization.</i><br/>
							<u>Kawin Ethayarajh</u>, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, and Douwe Kiela.<br/>
						      	ICML 2024 (<b>spotlight</b> - top 3.5% of accepted).<br/>
						    	<a href="https://arxiv.org/abs/2402.01306"><span class="label label-default">paper</span></a>
						    	<a href="https://x.com/ethayarajh/status/1732837520784957476"><span class="label label-info">tweet</span></a>
							<a href="https://github.com/ContextualAI/HALOs"><span class="label label-success">code</span></a>
							<a href="https://www.forbes.com/sites/robtoews/2024/02/04/what-is-the-best-way-to-control-todays-ai/"><span class="label label-danger">press</span></a>
						</li>
					</ul>
				</li>
			</ul>
		</p>
          </div>
      </div>
    </div> <!-- /container -->
  </body>
</html>
